{"cells":[{"cell_type":"code","execution_count":2,"metadata":{"colab":{"base_uri":"https://localhost:8080/"},"executionInfo":{"elapsed":19301,"status":"ok","timestamp":1662021606349,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"},"user_tz":-540},"id":"XltI_t_kUGvD","outputId":"a6bae395-0c40-49e0-8961-9218ca198655"},"outputs":[{"output_type":"stream","name":"stdout","text":["Mounted at /content/drive\n","/content/drive/.shortcut-targets-by-id/1j1N0u5t0l99N_wfSd5UZvnhugzn5g_NC/TimeSeriesAnomaly/data/modify\n"]}],"source":["from google.colab import drive\n","# drive.mount('/content/drive/MyDrive/IITP/sohyun/creditcard_prediction/data')\n","drive.mount('/content/drive')\n","\n","%cd drive/MyDrive/IITP/sohyun/TimeSeriesAnomaly/data/modify"]},{"cell_type":"code","execution_count":3,"metadata":{"id":"qi5fjXQLHQab","colab":{"base_uri":"https://localhost:8080/","height":277},"outputId":"0c063c08-e58f-4df2-f3bb-5af773e8cb42","executionInfo":{"status":"ok","timestamp":1662021629676,"user_tz":-540,"elapsed":19863,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[{"output_type":"stream","name":"stdout","text":["\u001b[K     |████████████████████████████████| 1.8 MB 14.8 MB/s \n","\u001b[K     |████████████████████████████████| 122 kB 62.4 MB/s \n","\u001b[K     |████████████████████████████████| 181 kB 62.8 MB/s \n","\u001b[K     |████████████████████████████████| 63 kB 1.4 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 73.1 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 70.7 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 72.9 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 75.5 MB/s \n","\u001b[K     |████████████████████████████████| 157 kB 61.6 MB/s \n","\u001b[K     |████████████████████████████████| 156 kB 57.4 MB/s \n","\u001b[?25h  Building wheel for pathtools (setup.py) ... \u001b[?25l\u001b[?25hdone\n"]},{"output_type":"stream","name":"stderr","text":["ERROR:wandb.jupyter:Failed to detect the name of this notebook, you can set it manually with the WANDB_NOTEBOOK_NAME environment variable to enable code saving.\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.Javascript object>"],"application/javascript":["\n","        window._wandbApiKey = new Promise((resolve, reject) => {\n","            function loadScript(url) {\n","            return new Promise(function(resolve, reject) {\n","                let newScript = document.createElement(\"script\");\n","                newScript.onerror = reject;\n","                newScript.onload = resolve;\n","                document.body.appendChild(newScript);\n","                newScript.src = url;\n","            });\n","            }\n","            loadScript(\"https://cdn.jsdelivr.net/npm/postmate/build/postmate.min.js\").then(() => {\n","            const iframe = document.createElement('iframe')\n","            iframe.style.cssText = \"width:0;height:0;border:none\"\n","            document.body.appendChild(iframe)\n","            const handshake = new Postmate({\n","                container: iframe,\n","                url: 'https://wandb.ai/authorize'\n","            });\n","            const timeout = setTimeout(() => reject(\"Couldn't auto authenticate\"), 5000)\n","            handshake.then(function(child) {\n","                child.on('authorize', data => {\n","                    clearTimeout(timeout)\n","                    resolve(data)\n","                });\n","            });\n","            })\n","        });\n","    "]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n"]},{"output_type":"execute_result","data":{"text/plain":["True"]},"metadata":{},"execution_count":3}],"source":["!pip install wandb -qqq\n","import wandb\n","wandb.login()"]},{"cell_type":"code","execution_count":4,"metadata":{"id":"gq_QRBw-_yqo","executionInfo":{"status":"ok","timestamp":1662021639101,"user_tz":-540,"elapsed":4277,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["import matplotlib.pyplot as plt\n","import easydict\n","from sklearn.preprocessing import StandardScaler\n","import random\n","import pandas as pd\n","import numpy as np\n","import os\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F\n","from torch.utils.data import Dataset, DataLoader\n","from tqdm.auto import tqdm\n","from sklearn.metrics import f1_score\n","import time\n","import math"]},{"cell_type":"markdown","metadata":{"id":"zjoJxI3iylhf"},"source":["## Data "]},{"cell_type":"code","execution_count":7,"metadata":{"executionInfo":{"elapsed":398,"status":"ok","timestamp":1662022503308,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"},"user_tz":-540},"id":"yH_ixp0aWdm4"},"outputs":[],"source":["#---# LOAD npy file #---#\n","Fu_20_normal = np.load('Fu_20_normal.npy')\n","Fu_21_normal = np.load('Fu_21_normal.npy')\n","Fu_21_abnormal = np.load('Fu_21_abnormal.npy')\n","Fu_22_normal = np.load('Fu_22_normal.npy')\n","Fu_22_abnormal = np.load('Fu_22_abnormal.npy')\n","\n","Fu_20_normal_10 = np.load('Fu_20_normal_10.npy')\n","Fu_21_normal_10 = np.load('Fu_21_normal_10.npy')\n","Fu_21_abnormal_10 = np.load('Fu_21_abnormal_10.npy')\n","Fu_22_normal_10 = np.load('Fu_22_normal_10.npy')\n","Fu_22_abnormal_10 = np.load('Fu_22_abnormal_10.npy')\n","\n","# import sys\n","# np.set_printoptions(threshold=sys.maxsize) # print all\n","\n","#---# 확인용 #---#\n","# plt.figure(figsize=(30,5))\n","# plt.plot(Fu_22_abnormal_10)"]},{"cell_type":"code","execution_count":11,"metadata":{"id":"fS479XwTHmk0","executionInfo":{"status":"ok","timestamp":1662022607000,"user_tz":-540,"elapsed":409,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["device = torch.device('cuda') if torch.cuda.is_available() else torch.device('cpu')\n","\n","class MyDataset(Dataset):\n","  def __init__(self, data):\n","    self.data = np.array(self.sliding_window(data, wandb.config.window_size, wandb.config.stride))\n","    self.data = self.data.reshape(-1, wandb.config.window_size)\n","    \n","  def __getitem__(self, index):\n","    self.x = self.data[index]\n","    return (index, torch.Tensor(self.x))\n","      \n","  def __len__(self):\n","    return len(self.data)\n","\n","  #---# Window #---#\n","  def sliding_window(self, arr, window_size, stride):\n","    start_pt = 0\n","    total_data = []\n","    while(True) :\n","      if len(arr) < (start_pt + window_size) : break\n","      data = arr[start_pt:start_pt+window_size]\n","      start_pt += stride\n","      total_data.append(data)\n","    return total_data\n","\n","class AutoEncoder(nn.Module):\n","  def __init__(self):\n","    super(AutoEncoder, self).__init__()\n","    self.Encoder = nn.Sequential(\n","      nn.Linear(config.window_size,200),\n","      nn.BatchNorm1d(200),\n","      nn.LeakyReLU(),\n","      nn.Linear(200,100),\n","      nn.BatchNorm1d(100),\n","      # nn.LeakyReLU(),\n","      # nn.Linear(100,50),\n","      # nn.BatchNorm1d(50),\n","\n","      # nn.LeakyReLU(),\n","      # nn.Linear(100,50),\n","      # nn.BatchNorm1d(50),\n","      nn.LeakyReLU()\n","    )\n","    self.Decoder = nn.Sequential(\n","      # nn.Linear(50,100),\n","      # nn.BatchNorm1d(100),\n","      # nn.LeakyReLU(),\n","      nn.Linear(100,200),\n","      nn.BatchNorm1d(200),\n","      nn.LeakyReLU(),\n","      # nn.Linear(100,200),\n","      # nn.BatchNorm1d(200),\n","      # nn.LeakyReLU(),\n","      # nn.Linear(200,400),\n","      # nn.BatchNorm1d(400),\n","      # nn.LeakyReLU(),\n","      nn.Linear(200,config.window_size),\n","    )\n","\n","    #####\n","    # self.Encoder = nn.Sequential(\n","    #   nn.Linear(config.window_size, 2*config.window_size),\n","    #   nn.BatchNorm1d(2*config.window_size),\n","    #   nn.LeakyReLU(),\n","    #   nn.Linear(2*config.window_size, 4*config.window_size),\n","    #   nn.BatchNorm1d(4*config.window_size),\n","    #   nn.LeakyReLU(),\n","    #   # nn.Linear(4*config.window_size, 8*config.window_size),\n","    #   # nn.BatchNorm1d(8*config.window_size),\n","    #   # nn.LeakyReLU()\n","    # )\n","    # self.Decoder = nn.Sequential(\n","    #   # nn.Linear(8*config.window_size, 4*config.window_size),\n","    #   # nn.BatchNorm1d(4*config.window_size),\n","    #   # nn.LeakyReLU(),\n","    #   nn.Linear(4*config.window_size, 2*config.window_size),\n","    #   nn.BatchNorm1d(2*config.window_size),\n","    #   nn.LeakyReLU(),\n","    #   nn.Linear(2*config.window_size, config.window_size),\n","    # )\n","    \n","  def forward(self, x):\n","    x = self.Encoder(x)\n","    x = self.Decoder(x)\n","    return x\n","\n","class Trainer():\n","  def __init__(self, model, optimizer, train_loader, scheduler, device):\n","    self.model = model\n","    self.optimizer = optimizer\n","    self.train_loader = train_loader\n","    self.scheduler = scheduler\n","    self.device = device\n","    # Loss Function\n","    # self.criterion = nn.L1Loss().to(self.device) ## L1 loss\n","    self.criterion = nn.CrossEntropyLoss().to(self.device) ## L2 loss\n","      \n","  def fit(self) :\n","    self.model.to(self.device)\n","    best_score = 0\n","    for epoch in range(wandb.config.num_epochs):\n","      self.model.train()\n","      train_loss = []\n","      for idx, x in iter(self.train_loader):\n","        x = x.float().to(self.device)\n","        self.optimizer.zero_grad()\n","        \n","        _x = self.model(x)\n","        loss = self.criterion(x, _x)\n","        \n","        loss.backward()\n","        self.optimizer.step()\n","\n","        train_loss.append(loss.item())\n","\n","      wandb.log({\n","              \"loss\": loss\n","          })\n","\n","      ####\n","      # score = self.validation(self.model, 0.95)\n","      # print(f'Epoch : [{epoch}] Train loss : [{np.mean(train_loss)}] Val Score : [{score}])')\n","\n","      # if self.scheduler is not None: self.scheduler.step(score)\n","\n","      # if best_score < score:\n","      #   best_score = score\n","      #   torch.save(model.module.state_dict(), './best_model.pth', _use_new_zipfile_serialization=False)\n","  \n","  def test(self, test_loader, thr) :\n","    cos = nn.CosineSimilarity(dim=1, eps=1e-6)\n","\n","    pred = []; true = []\n","    xs = []; _xs = []\n","    predictions = []\n","    total_num = math.floor((test.shape[0] - config.window_size) / config.stride)\n","\n","    self.model.eval()\n","    with torch.no_grad():\n","      for idx, x in iter(test_loader):\n","        x = x.float().to(self.device) # x shape : (batch_size, window_size)\n","        _x = self.model(x) # prediction\n","        \n","        for i in range(x.shape[0]) : # batch_size만큼 돌면서 stride씩만 저장\n","          if (idx[-1] == total_num) and (i == x.shape[0] - 1) : # 마지막 데이터는 전체 다 넣어주어야 함.\n","            xs.extend(x[i].numpy().tolist())\n","            _xs.extend(_x[i].numpy().tolist())\n","          else :\n","            xs.extend(x[i][0:config.stride].numpy().tolist())\n","            _xs.extend(_x[i][0:config.stride].numpy().tolist())\n","\n","\n","        diff = cos(x, _x).cpu().tolist()\n","        prediction = np.where(np.array(diff) < thr, 1, 0).tolist() # 1, 0이 들어감\n","        predictions.extend(prediction)\n","\n","    return predictions, xs, _xs\n","    # return f1_score(true, pred, average='macro')\n","\n","#####################\n","#---# functions #---#\n","#####################\n","def drawing(pred, x, _x) :\n","  plt.figure(figsize=(30,5))\n","  plt.plot(x, markersize=1)\n","  plt.plot(pred, marker='.', markersize=2, color='r', linestyle='None')\n","\n","  #---# 실제 anomaly 값 구간 #---#\n","  a = np.linspace(62200, 65300)\n","  plt.fill_between(a, 0, 2000, color='green', alpha=0.3)\n","  # plt.fill_between(a, -1, 4, color='green', alpha=0.5)\n","  b = np.linspace(95600, 99300)\n","  plt.fill_between(b, 0, 2000, color='green', alpha=0.3)\n","  # plt.fill_between(b, -1, 4, color='green', alpha=0.5)\n","  c = np.linspace(148400, 152300)\n","  plt.fill_between(c, 0, 2000, color='green', alpha=0.3)\n","  # plt.fill_between(c, -1, 4, color='green', alpha=0.5)\n","\n","  plt.show()\n","  plt.clf()\n","\n","def get_anomaly_time(original, prediction) : \n","  temp = pd.DataFrame(index=range(0, len(original)), columns={'Fu'})\n","  # temp = temp.fillna(0)\n","\n","  for i in range(len(prediction)) :\n","    if prediction[i] == 0 :\n","      for j in range(i*wandb.config.stride, (i*wandb.config.stride + wandb.config.window_size)) : \n","        temp.loc[j] = np.nan\n","\n","    elif prediction[i] == 1 : # anomaly\n","      for j in range(i*wandb.config.stride, (i*wandb.config.stride + wandb.config.window_size)) : \n","        try : temp.loc[j] = original[j]\n","        except : pass\n","\n","  # anomaly = temp.dropna()\n","  return temp\n","\n","def calculate(true_list, pred_list) : ### 이따 수정 예정\n","  pred_list = pred_list.dropna()\n","  pred_anomaly_set = set(pred_list.index.tolist())\n","  pred_normal_set = set(range(len(true_list))) - pred_anomaly_set\n","  true_anomaly_set = set(np.where(np.array(true_list) == 1)[0].tolist())\n","  true_normal_set = set(np.where(np.array(true_list) == 0)[0].tolist())\n","  recall = len(pred_anomaly_set.intersection(true_anomaly_set)) / len(true_anomaly_set)\n","  # accuracy = len(anomaly_set.intersection(true_set)) / len(anomaly_set.union(true_set))\n","\n","  accuracy = (len(pred_anomaly_set.intersection(true_anomaly_set)) + len(pred_normal_set.intersection(true_normal_set))) / len(true_list) # (빨간 거 맞은거 + 파란거 맞은거) / 전체\n","  return recall, accuracy"]},{"cell_type":"code","execution_count":12,"metadata":{"id":"MCqpW85kT5n8","executionInfo":{"status":"ok","timestamp":1662022610630,"user_tz":-540,"elapsed":573,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}}},"outputs":[],"source":["def main() :\n","  ##########################\n","  #---# true list 만들기 #---#\n","  ##########################\n","  true_label = [0 for i in range(len(x))] # test_scale\n","  true_label[62200:65300] = [1 for i in range(62200,65300)]\n","  true_label[95600:99300] = [1 for i in range(95600,99300)]\n","  true_label[148400:152300] = [1 for i in range(148400,152300)]\n","\n","  tm = time.localtime(time.time())\n","  string = time.strftime('%Y%m%d_%H%M%S', tm)\n","\n","  # wandb.init(project=\"Anomaly-Oil\", entity=\"sohyun\", name=string, magic=True)\n","\n","  train = pd.DataFrame(Fu_22_normal_10, columns=['Fu'])\n","  train = pd.concat([train, pd.DataFrame(Fu_21_normal_10, columns=['Fu']), pd.DataFrame(Fu_20_normal_10, columns=['Fu'])], axis=0)\n","  test = pd.DataFrame(Fu_22_abnormal_10, columns=['Fu'])\n","  test_len = len(test)\n","  total = pd.DataFrame(pd.concat([train, test], axis=0))\n","\n","  train_scale = train['Fu'].values\n","  test_scale = test['Fu'].values\n","  total_scale = total['Fu'].values\n","\n","  #---# Noramlize #---#\n","  # scaler = StandardScaler()\n","  # total_scale = scaler.fit_transform(total); total_scale = pd.DataFrame(total_scale, columns=['Fu'])['Fu'].values.tolist() # total 먼저 해놓고 transform\n","  # train_scale = scaler.transform(train); train_scale = pd.DataFrame(train_scale, columns=['Fu'])['Fu'].values.tolist()\n","  # test_scale = scaler.transform(test); test_scale = pd.DataFrame(test_scale, columns=['Fu'])['Fu'].values.tolist()\n","\n","  #---# Setting train data #---#\n","  train_dataset = MyDataset(data=train_scale)\n","  train_loader = DataLoader(train_dataset, batch_size=wandb.config.batch_size, shuffle=True, drop_last=True)\n","  test_dataset = MyDataset(data=test_scale)\n","  test_loader = DataLoader(test_dataset, batch_size=wandb.config.batch_size, shuffle=False)\n","\n","  # model = nn.DataParallel(AutoEncoder())\n","  model = AutoEncoder()\n","\n","  optimizer = torch.optim.Adam(params = model.parameters(), lr = config.lr) # lr = config.lr\n","  scheduler = torch.optim.lr_scheduler.ReduceLROnPlateau(optimizer, mode='max', factor=0.5, patience=10, threshold_mode='abs', min_lr=1e-8, verbose=True)\n","\n","  trainer = Trainer(model, optimizer, train_loader, scheduler, device)\n","  trainer.fit()\n","  pred, x, _x = trainer.test(test_loader, wandb.config.threshold)\n","\n","  a = get_anomaly_time(x, pred)\n","  recall, accuracy = calculate(true_label, a)\n","\n","  drawing(a, x, _x) # draw plot\n","  print(f\"===== RECALL ======\\n{recall}\\n====== ACCURACY =====\\n{accuracy}\")\n","\n"]},{"cell_type":"code","source":["# config = easydict.EasyDict({\n","#     \"num_epochs\" : 200, #500\n","#     \"batch_size\" : 16, #16 \n","#     \"mode\" : 'train',\n","#     # \"mode\" : \"test\",\n","#     \"lr\" : 1e-3, \n","#     \"wd\" : None,\n","#     \"window_size\" : 1000,\n","#     \"stride\" : 500,\n","#     \"threshold\" : 0.3 # 0.3이나 0.2로 하기\n","# })\n","\n","config = {\n","    'method' : 'grid',\n","    'parameters' : {\n","        'lr' :{'values' : [1e-3]}, #1e-6, 1e-5, 1e-4, 1e-3, 1e-2, 1e-1\n","        'batch_size' :{'values' : [8]},\n","        'window_size' : {'values' : [800, 1000]},\n","        'stride' : {'values' : [200, 250]},\n","        'threshold' :{'values' : [0.1, 0.3, 0.5, 0.7, 0.9]}\n","    }\n","}\n","tm = time.localtime(time.time())\n","string = time.strftime('%Y%m%d_%H%M%S', tm)\n","\n","wandb.init(project=\"Anomaly-Oil\", entity=\"sohyun\", name=string, magic=True)\n","sweep_id = wandb.sweep(config, project=\"Anomaly_oil\")\n","wandb.agent(sweep_id, function=main)"],"metadata":{"id":"ud1EwYw4cNvj","colab":{"base_uri":"https://localhost:8080/","height":780},"executionInfo":{"status":"error","timestamp":1662022518843,"user_tz":-540,"elapsed":6992,"user":{"displayName":"아이덴티파이ai","userId":"09195867153538576050"}},"outputId":"27f54ba1-0e8c-45f5-b4ef-1c5c08925e25"},"execution_count":10,"outputs":[{"output_type":"stream","name":"stderr","text":["\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33msohyun\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n"]},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Tracking run with wandb version 0.13.2"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Run data is saved locally in <code>/content/drive/.shortcut-targets-by-id/1j1N0u5t0l99N_wfSd5UZvnhugzn5g_NC/TimeSeriesAnomaly/data/modify/wandb/run-20220901_085511-1rf7javv</code>"]},"metadata":{}},{"output_type":"display_data","data":{"text/plain":["<IPython.core.display.HTML object>"],"text/html":["Syncing run <strong><a href=\"https://wandb.ai/sohyun/Anomaly-Oil/runs/1rf7javv\" target=\"_blank\">20220901_085511</a></strong> to <a href=\"https://wandb.ai/sohyun/Anomaly-Oil\" target=\"_blank\">Weights & Biases</a> (<a href=\"https://wandb.me/run\" target=\"_blank\">docs</a>)<br/>"]},"metadata":{}},{"output_type":"stream","name":"stderr","text":["Traceback (most recent call last):\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 1040, in init\n","    wi.setup(kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\", line 247, in setup\n","    magic_install(kwargs)\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/integration/magic.py\", line 542, in magic_install\n","    _monkey_tfkeras()\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/integration/magic.py\", line 339, in _monkey_tfkeras\n","    from wandb.integration.keras import WandbCallback  # add keras import hooks first\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/__init__.py\", line 7, in <module>\n","    from .keras import WandbCallback\n","  File \"/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\", line 20, in <module>\n","    import tensorflow.keras.backend as K\n","ModuleNotFoundError: No module named 'tensorflow.keras'\n","\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[32m\u001b[41mERROR\u001b[0m Abnormal program exit\n"]},{"output_type":"error","ename":"Exception","evalue":"ignored","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1039\u001b[0m         \u001b[0mwi\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_WandbInit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1040\u001b[0;31m         \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msetup\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1041\u001b[0m         \u001b[0mexcept_exit\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwi\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msettings\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_except_exit\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36msetup\u001b[0;34m(self, kwargs)\u001b[0m\n\u001b[1;32m    246\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmagic\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 247\u001b[0;31m             \u001b[0mmagic_install\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    248\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/magic.py\u001b[0m in \u001b[0;36mmagic_install\u001b[0;34m(init_args)\u001b[0m\n\u001b[1;32m    541\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0;34m\"tensorflow.python.keras\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m\"keras\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msys\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodules\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 542\u001b[0;31m             \u001b[0m_monkey_tfkeras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    543\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/magic.py\u001b[0m in \u001b[0;36m_monkey_tfkeras\u001b[0;34m()\u001b[0m\n\u001b[1;32m    338\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0m_monkey_tfkeras\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 339\u001b[0;31m     \u001b[0;32mfrom\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mintegration\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m  \u001b[0;31m# add keras import hooks first\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    340\u001b[0m     \u001b[0;32mfrom\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mkeras\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtfkeras\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/__init__.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mWandbCallback\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/integration/keras/keras.py\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     19\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mtf\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 20\u001b[0;31m \u001b[0;32mimport\u001b[0m \u001b[0mtensorflow\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeras\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mbackend\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mK\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     21\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'tensorflow.keras'","\nThe above exception was the direct cause of the following exception:\n","\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)","\u001b[0;32m<ipython-input-10-1d856a06ce7f>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0mstring\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%Y%m%d_%H%M%S'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mtm\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     25\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 26\u001b[0;31m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0minit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Anomaly-Oil\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mentity\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"sohyun\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmagic\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     27\u001b[0m \u001b[0msweep_id\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msweep\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mconfig\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mproject\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"Anomaly_oil\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     28\u001b[0m \u001b[0mwandb\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0magent\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msweep_id\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mfunction\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmain\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;32m/usr/local/lib/python3.7/dist-packages/wandb/sdk/wandb_init.py\u001b[0m in \u001b[0;36minit\u001b[0;34m(job_type, dir, config, project, entity, reinit, tags, group, name, notes, magic, config_exclude_keys, config_include_keys, anonymous, mode, allow_val_change, resume, force, tensorboard, sync_tensorboard, monitor_gym, save_code, id, settings)\u001b[0m\n\u001b[1;32m   1079\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mexcept_exit\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1080\u001b[0m                 \u001b[0mos\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_exit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1081\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"problem\"\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfrom\u001b[0m \u001b[0merror_seen\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1082\u001b[0m     \u001b[0;32mreturn\u001b[0m \u001b[0mrun\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n","\u001b[0;31mException\u001b[0m: problem"]}]},{"cell_type":"code","source":[],"metadata":{"id":"jQoQOOtBhcXl"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"OK3w5Cr8v5dJ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"vA2G0vWmv5Wo"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"gY-C_kr7v5TQ"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"XbMQF9uNv5Oz"},"execution_count":null,"outputs":[]},{"cell_type":"code","source":[],"metadata":{"id":"ubS_Nsgqv5Ke"},"execution_count":null,"outputs":[]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[],"authorship_tag":"ABX9TyMG7gXtwkwMHqSUmWSSUh5T"},"kernelspec":{"display_name":"Python 3","name":"python3"},"language_info":{"name":"python"}},"nbformat":4,"nbformat_minor":0}